{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Twitter API Keys\n",
    "from config import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "prevTwitterFile = \"Resources/past_twitter_analysis.txt\"\n",
    "imageAnalysisFile = \"Images/sentiment.png\"\n",
    "myTwitterHandle = \"@elev8r_music\"\n",
    "tweetBotPhrase = \"analyze:\"\n",
    "my_since_id = None\n",
    "\n",
    "# List for tweets to analysis\n",
    "tweetTextArray = []\n",
    "# Twitter Handle to analyze\n",
    "twitterToAnalyze = \"\"\n",
    "# Twitter Handle of requester\n",
    "twitterRequester = \"\"\n",
    "\n",
    "# Global lists for sentiment analysis\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "# global data frame for sentiment analysis\n",
    "sentiment_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks against list of twitter handles previously analyzed.\n",
    "# Returns None if previously analyzed, otherwise return twitter handle to analyze\n",
    "def checkTwitterAccount(user):\n",
    "    userToAnalyze = user.replace(\"@\", \"\")\n",
    "    userToAnalyze = userToAnalyze.strip()\n",
    "    with open(prevTwitterFile, \"a+\") as file:\n",
    "        file.seek(0)\n",
    "        for line in file:\n",
    "            line = line.strip() # preprocess line for string comparison\n",
    "            # check if twitter handle has been analyzed previously\n",
    "            if(userToAnalyze == line):\n",
    "                userToAnalyze = None\n",
    "                #print(\"Twitter account previously analyzed.\")\n",
    "                break\n",
    "        # If never been analyzed add to list\n",
    "        if(userToAnalyze != None):\n",
    "            file.write(f\"{userToAnalyze}\\n\")\n",
    "            return(user)\n",
    "    return None\n",
    "# end function checkTwitterAccount\n",
    "\n",
    "#print(checkTwitterAccount(\"@cnn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parses tweet to look for pattern to begin bot analysis\n",
    "# Phrase struct is \"@{myTwitterHandle} {tweetBotPhrase} {twitter_handle_to_analyze}\"\n",
    "# Returns none if pattern doesn't match, otherwise return twitter handle to analyze\n",
    "def parseTweet(tweet):\n",
    "    #print(tweet)\n",
    "    # split on spaces...allow multiple spaces between words\n",
    "    tweet_split = re.split('\\s+', tweet)\n",
    "    # check length\n",
    "    if(len(tweet_split) < 3):\n",
    "        return None\n",
    "    # make sure they specified a twitter handle\n",
    "    elif(tweet_split[2] == \"\"):\n",
    "        return None\n",
    "    # check for correct pattern format and return twitter handle to analyze\n",
    "    elif(tweet_split[0].lower() == myTwitterHandle and \n",
    "       tweet_split[1].lower() == tweetBotPhrase\n",
    "      ):\n",
    "        return tweet_split[2].strip().lower()\n",
    "    else:\n",
    "        return None\n",
    "# end function parseTweet\n",
    "\n",
    "#test_text = \"@elev8r_music analyze: @CNN\"\n",
    "#print(parseTweet(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requests last 500 tweets from twitterHandle\n",
    "# Returns None if error else returns number of tweets recorded\n",
    "def getTwitterData(twitterHandle):\n",
    "    global tweetTextArray\n",
    "    oldest_tweet_id = None\n",
    "    counter = 1\n",
    "    # Clear previous tweets from global\n",
    "    tweetTextArray.clear()\n",
    "    #print(twitterHandle)\n",
    "    # Get last 500 tweets\n",
    "    for x in range(5): \n",
    "        try:\n",
    "            # Get all tweets from home feed\n",
    "            public_tweets = api.user_timeline(twitterHandle, count=100, page=x, max_id = oldest_tweet_id)\n",
    "        except tweepy.TweepError:\n",
    "            return None\n",
    "        # collect tweets for VADAR Analysis\n",
    "        for tweet in public_tweets:\n",
    "            #print(f\"{counter}: {tweet['text']}\")\n",
    "            tweetTextArray.append(tweet['text'])\n",
    "            counter += 1\n",
    "            # assign tweet id to make sure we don't get overlapping tweets\n",
    "            oldest_tweet_id = tweet['id'] - 1\n",
    "    # return the number of tweets analyzed\n",
    "    return (len(tweetTextArray))\n",
    "# end function getTwitterData\n",
    "\n",
    "#tweetCount = getTwitterData(\"@CNN\")\n",
    "#print(tweetCount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(tweetTextArray))\n",
    "#print(tweetTextArray[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs VADAR analysis on tweet texts gathered in tweetTextArray\n",
    "def performVadarAnalysis():\n",
    "    global compound_list, positive_list, negative_list, neutral_list, tweetTextArray\n",
    "    # Clear lists of previous analysis\n",
    "    compound_list.clear()\n",
    "    positive_list.clear()\n",
    "    negative_list.clear()\n",
    "    neutral_list.clear()\n",
    "    \n",
    "    # Add results to lists\n",
    "    for tweetText in tweetTextArray:\n",
    "        results = analyzer.polarity_scores(tweetText)\n",
    "        compound_list.append(results['compound'])\n",
    "        positive_list.append(results['pos'])\n",
    "        negative_list.append(results['neg'])\n",
    "        neutral_list.append(results['neu'])\n",
    "        \n",
    "    # Reverse so that when graphing it will correspond to time passing\n",
    "    compound_list.reverse()\n",
    "    positive_list.reverse()\n",
    "    negative_list.reverse()\n",
    "    neutral_list.reverse()\n",
    "# End of performSentimentAnalyze\n",
    "\n",
    "#performVadarAnalysis()\n",
    "#sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create color array for bar graph\n",
    "def createColorArray(sentiment):\n",
    "    #For sentiment greater than or zero use green\n",
    "    if(sentiment >= 0):\n",
    "        return 'g'\n",
    "    else:\n",
    "        return 'r'\n",
    "# End of createColorArray\n",
    "\n",
    "# Function to plot the analysis and create picture\n",
    "def plotSentimentAnalysis():\n",
    "    global compound_list, positive_list, negative_list, neutral_list, sentiment_df\n",
    "    # Create a dataframe of analysis\n",
    "    sentiment_df = pd.DataFrame({\n",
    "        \"Compound\": compound_list,\n",
    "        \"Positive\": positive_list,\n",
    "        \"Negative\": negative_list,\n",
    "        \"Neutral\": neutral_list})\n",
    "    # Create x_axis\n",
    "    x_axis = np.arange(-len(sentiment_df), 0)\n",
    "    # Create y_axis\n",
    "    y_axis = sentiment_df['Compound']\n",
    "    # Create color array\n",
    "    colors = [createColorArray(sentiment) for sentiment in y_axis]\n",
    "    # plot bar graph\n",
    "    plt.bar(x_axis, y_axis, color=colors, width=2)\n",
    "    # Incorporate the other graph properties\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%Y-%m-%d %H:%M\")\n",
    "    plt.title(f\"VADAR Analysis of Tweets of {twitterToAnalyze} ({now})\")\n",
    "    plt.ylabel(\"Tweet Polarity\")\n",
    "    plt.xlabel(\"Tweets Ago\")\n",
    "    plt.xlim(-len(sentiment_df), 1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(imageAnalysisFile)\n",
    "    #plt.show()\n",
    "# End of plotSentimentAnalysis\n",
    "    \n",
    "#plotSentimentAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check my timeline for new tweets\n",
    "def checkMyTimeline():\n",
    "    global my_since_id\n",
    "    try:\n",
    "        my_tweets = api.home_timeline(since_id = my_since_id, count=100)\n",
    "    except tweepy.TweepError:\n",
    "        return None\n",
    "    # Check if new tweets retrieved\n",
    "    if(len(my_tweets) > 0):\n",
    "        my_since_id = my_tweets[0]['id']\n",
    "        return my_tweets\n",
    "    else:\n",
    "        return None\n",
    "# End of checkMyTimeline\n",
    "\n",
    "#tweets = checkMyTimeline()\n",
    "#for tweet in tweets:\n",
    "#    print(tweet['user']['screen_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posts results to my timeline with analysis figure\n",
    "def postResultsToTimeline():\n",
    "    tweet = api.update_with_media(imageAnalysisFile,\n",
    "                          f\"New tweet analysis: {twitterToAnalyze} (For: @{twitterRequester})\")\n",
    "    return tweet\n",
    "# End of postResultsToTimeline\n",
    "\n",
    "#postTweet = postResultsToTimeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api.destroy_status(postTweet['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main logic for twitter bot execution\n",
    "def twitterBotMain():\n",
    "    global twitterRequester, twitterToAnalyze\n",
    "    # check my timeline for new tweets\n",
    "    myTweets = checkMyTimeline()\n",
    "    if(myTweets != None):\n",
    "        # Look through tweeets for matching pattern\n",
    "        for tweet in myTweets:\n",
    "            twitterHandle = parseTweet(tweet['text'])\n",
    "            if(twitterHandle != None):\n",
    "                # Check if twitter handle was previously analyzed\n",
    "                twitterToAnalyze = checkTwitterAccount(twitterHandle)\n",
    "                if(twitterToAnalyze != None):\n",
    "                    # Do analysis\n",
    "                    twitterRequester = tweet['user']['screen_name']\n",
    "                    print(f\"Analyze: {twitterToAnalyze} for {twitterRequester}\")\n",
    "                    tweetCount = getTwitterData(twitterToAnalyze)\n",
    "                    performVadarAnalysis()\n",
    "                    plotSentimentAnalysis()\n",
    "                    postTweet = postResultsToTimeline()\n",
    "                    #print(postTweet['id'])\n",
    "                else:\n",
    "                    print(\"Twitter previously handled\")\n",
    "            else:\n",
    "                print(\"No Handle returned\")\n",
    "    else:\n",
    "        print(\"No new tweets\")\n",
    "    #check again in 5 minutes\n",
    "    time.sleep(300)    \n",
    "# End of twitterBotMain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing main\n",
    "while True:\n",
    "    twitterBotMain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
